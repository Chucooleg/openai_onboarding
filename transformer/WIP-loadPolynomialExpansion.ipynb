{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchucooleg\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import math\n",
    "import json\n",
    "from typing import Callable, Iterable, Tuple\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "from pytorch_lightning.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Depth 1\n",
    "\n",
    "def construct_full_model(hparams):\n",
    "    '''\n",
    "    return: nn.Module. Take a sequence of input symbols and \n",
    "    return a sequence of output symbols\n",
    "    '''\n",
    "\n",
    "    # cloned\n",
    "    clone = copy.deepcopy\n",
    "    pff = Positiontwise_FF(d_model=hparams['d_model'], d_ff=hparams['d_ff'])\n",
    "    attn = MultiHeadAttention(\n",
    "        d_model=hparams['d_model'], \n",
    "        h=hparams['num_heads'], \n",
    "        attn_wt_dropout=hparams['attn_wt_dropout'],\n",
    "    )\n",
    "    layer_norm = LayerNorm(d_model=hparams['d_model'])\n",
    "\n",
    "    # shared\n",
    "    scaled_embed = ScaledEmbedding(hparams['vocab_size'], hparams['d_model'])\n",
    "    position_encoder = PositionEncoder(\n",
    "        d_model=hparams['d_model'], max_len=hparams['max_len']\n",
    "    )\n",
    "    embed_dropout = nn.Dropout(hparams['embed_dropout'])\n",
    "\n",
    "    # full model\n",
    "    model = EncoderDecoder(\n",
    "        encoder=Encoder(\n",
    "            encoder_layer=EncoderLayer(\n",
    "                poswise_ff=clone(pff),\n",
    "                self_attn=clone(attn), \n",
    "                layer_norm=clone(layer_norm), \n",
    "                heads_dropout=hparams['heads_dropout'],\n",
    "                pff_dropout=hparams['pff_dropout']\n",
    "            ), \n",
    "            N_layers=hparams['N_enc'],\n",
    "            d_model=hparams['d_model'],\n",
    "        ),\n",
    "        decoder=Decoder(\n",
    "            decoder_layer=DecoderLayer(\n",
    "                poswise_ff=clone(pff),\n",
    "                self_attn=clone(attn), \n",
    "                cross_attn=clone(attn), \n",
    "                layer_norm=clone(layer_norm), \n",
    "                heads_dropout=hparams['heads_dropout'],\n",
    "                pff_dropout=hparams['pff_dropout']\n",
    "            ),\n",
    "            N_layers=hparams['N_dec'],\n",
    "            d_model=hparams['d_model'],\n",
    "        ),\n",
    "        classifier=Classifier(\n",
    "            shared_embed=scaled_embed.embedding\n",
    "        ),\n",
    "        inp_layer=nn.Sequential(\n",
    "            OrderedDict([('scaled_embed', scaled_embed), \n",
    "                        ('position_encoder', position_encoder),\n",
    "                        ('embed_dropout', embed_dropout)]\n",
    "            )\n",
    "        ),\n",
    "        out_layer=nn.Sequential(\n",
    "            OrderedDict([('scaled_embed', scaled_embed), \n",
    "                        ('position_encoder', position_encoder),\n",
    "                        ('embed_dropout', embed_dropout)]\n",
    "            )\n",
    "        ),\n",
    "        pad_idx=hparams['padding_idx']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Depth 2\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, classifier, inp_layer, out_layer, pad_idx):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.classifier = classifier\n",
    "        self.inp_layer = inp_layer\n",
    "        self.out_layer = out_layer\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    # def forward(self, X, Y, inp_pads, out_pads):\n",
    "    def forward(self, X, Y):\n",
    "        '''\n",
    "        Args\n",
    "        X : a sequence of input symbols. shape(batch_size=b, inp_len)\n",
    "        Y : a sequence of output symbols. shape(batch_size=b, out_len)\n",
    "            offset to the right by one position.\n",
    "        Returns\n",
    "        y_pred : predicted probabilities. shape(batch_size=b, out_len, V)\n",
    "                should be offset by one position to be fed into decoder.\n",
    "        '''\n",
    "        # shape(batch_size=b, inp_len)\n",
    "        inp_pads = (X == self.pad_idx).int()\n",
    "        # shape(batch_size=b, out_len)\n",
    "        out_pads = (Y == self.pad_idx).int()\n",
    "\n",
    "        # shape(b, inp_len, d_model)\n",
    "        encoder_out = self.encode(X, inp_pads)\n",
    "        # shape(b, out_len, d_model)\n",
    "        decoder_out = self.decode(encoder_out, Y, inp_pads, out_pads)\n",
    "        # shape (b, out_len, V)\n",
    "        out_logits = self.classifier(decoder_out)\n",
    "\n",
    "        return out_logits\n",
    "\n",
    "    def encode(self, X, inp_pads):\n",
    "        # shape(b, inp_len, d_model)\n",
    "        inp_embed = self.inp_layer(X)\n",
    "        # shape(b, inp_len, d_model)\n",
    "        encoder_out = self.encoder(inp_embed, inp_pads)\n",
    "        return encoder_out\n",
    "\n",
    "    def decode(self, encoder_out, Y, inp_pads, out_pads):\n",
    "        # shape(b, out_len, d_model)\n",
    "        out_embed = self.out_layer(Y)\n",
    "        # shape(b, out_len, d_model)\n",
    "        decoder_out = self.decoder(encoder_out, out_embed, inp_pads, out_pads)\n",
    "        return decoder_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Depth 3\n",
    "# http://karlstratos.com/notes/transformer17.pdf\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder_layer, N_layers, d_model):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder_layers = nn.ModuleList(\n",
    "            [copy.deepcopy(encoder_layer) for _ in range(N_layers)])\n",
    "        self.N_layers = N_layers\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, inp_embedding, inp_pads):\n",
    "        \"\"\"\n",
    "        Args\n",
    "        inp_embedding: Input embeddings. Already position encoded.\n",
    "                        shape (batch_size=b, inp_len, d_model)\n",
    "        inp_pads: Input pads. shape (batch_size=b, inp_len). 1s are padded.\n",
    "        Returns\n",
    "        encoder_out: output from encoder stack. \n",
    "                    shape (batch_size=b, inp_len, d_model)\n",
    "        \"\"\"\n",
    "        m, inp_len, d_model = inp_embedding.shape\n",
    "\n",
    "        # Make self-attn mask\n",
    "        self_attn_mask = make_attn_mask(inp_pads, inp_pads, mask_forward=False)\n",
    "\n",
    "        # Initiate encoder output tensor\n",
    "        encoder_out = torch.empty(\n",
    "            m, self.N_layers, inp_len, self.d_model).type_as(inp_embedding)\n",
    "\n",
    "        # Loop through layers in stack\n",
    "        last_z = inp_embedding\n",
    "        for l, encoder_layer in enumerate(self.encoder_layers):\n",
    "            # shape (b, inp_len, d_model)\n",
    "            last_z, _ = encoder_layer(last_z, self_attn_mask)\n",
    "#             print(\"encoder layer\",l)\n",
    "            encoder_out[:, l, :, :] = last_z\n",
    "\n",
    "        return encoder_out\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, decoder_layer, N_layers, d_model):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder_layers = nn.ModuleList(\n",
    "            [copy.deepcopy(decoder_layer) for _ in range(N_layers)])\n",
    "        self.N_layers = N_layers\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, encoder_out, out_embedding, \n",
    "                inp_pads, out_pads, max_decode=100):\n",
    "        \"\"\"\n",
    "        Args\n",
    "        encoder_out: output from encoder stack.\n",
    "                    shape (batch_size=b, N_enc, inp_len, d_model)\n",
    "        out_embedding: Output embedding. Shape (batch_size=b, out_len, d_model)\n",
    "                    Already position encoded. Offset by one position.\n",
    "        inp_pads: Input pads. shape (batch_size=b, inp_len). 1s are padded.\n",
    "        out_pads: Input pads. shape (batch_size=b, out_len). 1s are padded.\n",
    "        Returns\n",
    "            decoder_out: output from decoder stack\n",
    "        \"\"\"\n",
    "        # b, N_enc, inp_len, d_model = encoder_out.shape\n",
    "        # b, out_len, d_model = out_embedding.shape\n",
    "\n",
    "        self_attn_mask = make_attn_mask(out_pads, out_pads, mask_forward=True)\n",
    "        cross_attn_mask = make_attn_mask(out_pads, inp_pads, mask_forward=False)\n",
    "\n",
    "        # Loop through layers in stack\n",
    "        last_o = out_embedding\n",
    "        for l, decoder_layer in enumerate(self.decoder_layers):\n",
    "            # shape (b, out_len, d_model)\n",
    "            last_o, _, _ = decoder_layer(\n",
    "                last_o, \n",
    "                # encoder_out[:, -1, :, :],\n",
    "                encoder_out[:, l, :, :],\n",
    "                self_attn_mask, cross_attn_mask\n",
    "            )\n",
    "        decoder_output = last_o\n",
    "        return decoder_output\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, shared_embed):\n",
    "        '''\n",
    "        shared_embed: same embedding matrix as the input and output layers.\n",
    "                    shape(V, d_model)\n",
    "        '''\n",
    "        super(Classifier, self).__init__()\n",
    "        self.shared_embed = shared_embed\n",
    "\n",
    "    def forward(self, decoder_out):\n",
    "        '''\n",
    "        decoder_out: last layer output of decoder stack. \n",
    "                 shape(batch_size=b, out_len, d_model)\n",
    "        '''\n",
    "        # shape (b, out_len, d_model) mm (d_model, V) = (b, out_len, V)\n",
    "        logits = decoder_out.matmul(self.shared_embed.weight.t())\n",
    "        # # shape (b, out_len, V) too expensive to compute everytime\n",
    "        # probs = torch.softmax(logits, dim=-1)\n",
    "        return logits #, probs\n",
    "\n",
    "\n",
    "class ScaledEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, V, d_model):\n",
    "        super(ScaledEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(V, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        '''\n",
    "        tokens: shape (batch_size=b, len)\n",
    "        '''\n",
    "        # shape (b, len, d_model)\n",
    "        embedded = self.embedding(tokens) * math.sqrt(self.d_model)\n",
    "        if torch.max(embedded) > 2000.:\n",
    "            import pdb; pdb.set_trace()\n",
    "        return embedded\n",
    "\n",
    "\n",
    "class PositionEncoder(nn.Module):\n",
    "    # Alternative implementation\n",
    "    # https://github.com/jalammar/jalammar.github.io/blob/master/notebookes/transformer/transformer_positional_encoding_graph.ipynb\n",
    "\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super(PositionEncoder, self).__init__()\n",
    "        # even\n",
    "        # i = 0, 2, 4, 6, ..., 510\n",
    "        # j = 0, 1, 2, 3, ..., 255\n",
    "        # PE(pos, i=2j) = sin(pos/10000**(2*j/d_model))\n",
    "        # odd\n",
    "        # i = 1, 3, 5, 7, ..., 511\n",
    "        # j = 0, 1, 2, 3, ..., 255\n",
    "        # PE(pos, i=2j+1) = cos(pos/10000**(2*j/d_model))\n",
    "        # shape(256,)\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "        self.register_buffer(\n",
    "            name=\"positional_encoding\", \n",
    "            tensor=self.make_encodings(self.d_model, self.max_len)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def make_encodings(d_model, max_len):\n",
    "        # shape (d_model/2)\n",
    "        div_terms = torch.pow(\n",
    "            10000, \n",
    "            2*torch.arange(start=0, # j = 0\n",
    "                       end=d_model/2 # j = 255\n",
    "            )/d_model\n",
    "        )\n",
    "\n",
    "        # shape (max_len,) -> shape (max_len, d_model)\n",
    "        positions = torch.arange(\n",
    "            max_len\n",
    "            ).unsqueeze(-1).expand(-1, d_model)\n",
    "\n",
    "        # shape (max_len, d_model)\n",
    "        positional_encoding = torch.empty(\n",
    "            max_len, d_model, dtype=torch.float, \n",
    "        )\n",
    "    \n",
    "        # shape (max_len, d_model/2)\n",
    "        pos_at_even_dims = positions[:, ::2]\n",
    "        # shape (max_len, d_model/2)\n",
    "        pos_at_odd_dims  = positions[:, 1::2]\n",
    "\n",
    "        # shape (max_len, d_model/2)\n",
    "        div_terms_expand = div_terms.unsqueeze(0).expand(max_len, -1)\n",
    "\n",
    "        # shape (max_len, d_model/2)\n",
    "        positional_encoding[:, ::2] = torch.sin(pos_at_even_dims / div_terms_expand)\n",
    "        # shape (max_len, d_model/2)\n",
    "        positional_encoding[:, 1::2] = torch.cos(pos_at_odd_dims / div_terms_expand)\n",
    "\n",
    "        # shape (max_len, d_model)\n",
    "        return positional_encoding\n",
    "\n",
    "    def forward(self, embedded):\n",
    "        '''\n",
    "        embedded: shape (batch_size=b, len, d_model)\n",
    "        '''\n",
    "        b, len, d_model = embedded.shape\n",
    "        assert len <= self.max_len\n",
    "        # shape (batch_size=b, len, d_model)\n",
    "        positional_encoding = (\n",
    "            self.positional_encoding[:len, :].unsqueeze(0).expand(b, -1, -1)\n",
    "        )\n",
    "        # shape (batch_size=b, len, d_model)\n",
    "        return positional_encoding + embedded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing positional encoder\n",
    "\n",
    "def test_positional_encoder(PositionEncoder, max_len=10, d_model=64):\n",
    "    # test positional encoding\n",
    "    b, len, d_model = 20, max_len, d_model\n",
    "    embedding = torch.randn(b, len, d_model)\n",
    "    pos_enc = PositionEncoder(d_model, 50)\n",
    "    positional_encoding = pos_enc.positional_encoding\n",
    "    plot_positional_encoding(positional_encoding)\n",
    "\n",
    "def plot_positional_encoding(positional_encoding):\n",
    "    '''\n",
    "    positional_encoding: tensor shape (len, d_model)\n",
    "    '''\n",
    "\n",
    "    tokens, dimensions = positional_encoding.shape\n",
    "  \n",
    "    pos_encoding = positional_encoding.unsqueeze(0).cpu().numpy()\n",
    "\n",
    "    print (pos_encoding.shape)\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.pcolormesh(pos_encoding[0], cmap='viridis')\n",
    "    plt.xlabel('Embedding Dimensions')\n",
    "    plt.xlim((0, dimensions))\n",
    "    plt.ylim((tokens,0))\n",
    "    plt.ylabel('Token Position')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "test_positional_encoder(PositionEncoder, d_model=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Depth 4\n",
    "# http://karlstratos.com/notes/transformer17.pdf\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    '''\n",
    "    single layer encoder\n",
    "    '''\n",
    "    def __init__(self, poswise_ff, self_attn, layer_norm,\n",
    "                heads_dropout, pff_dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.poswise_ff = poswise_ff\n",
    "        self.self_attn = self_attn\n",
    "        self.layer_norms = nn.ModuleList([copy.deepcopy(layer_norm) for _ in range(2)])\n",
    "        self.heads_dropout = nn.Dropout(heads_dropout)\n",
    "        self.pff_dropout = nn.Dropout(pff_dropout)\n",
    "\n",
    "    def forward(self, z_lm1, self_attn_mask):\n",
    "        '''\n",
    "        z_lm1 : last encoder layer activations. shape (batch_size=b, inp_len, d_model)\n",
    "        '''\n",
    "\n",
    "        # (b, inp_len, d_model)\n",
    "        z_lm1_h, self_attn_wts = self.self_attn(z_lm1, z_lm1, self_attn_mask)\n",
    "        # (b, inp_len, d_model)\n",
    "        z_lm1_h_norm = self.layer_norms[0](z_lm1 + self.heads_dropout(z_lm1_h))\n",
    "        # (b, inp_len, d_model)\n",
    "        z_lm1_ff = self.poswise_ff(z_lm1_h_norm)\n",
    "        # (b, inp_len, d_model)\n",
    "        z_l = self.layer_norms[1](z_lm1_h_norm + self.pff_dropout(z_lm1_ff))\n",
    "        \n",
    "        if torch.isinf(z_l).any() or torch.isnan(z_l).any():\n",
    "            print(\"z_l is nan or inf\")\n",
    "            import pdb; pdb.set_trace()\n",
    "        \n",
    "        return z_l, self_attn_wts\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    '''\n",
    "    single layer decoder\n",
    "    '''\n",
    "    def __init__(self, poswise_ff, self_attn, cross_attn, \n",
    "                layer_norm, heads_dropout, pff_dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.poswise_ff = poswise_ff\n",
    "        self.self_attn = self_attn\n",
    "        self.cross_attn = cross_attn\n",
    "        self.layer_norms = nn.ModuleList([copy.deepcopy(layer_norm) for _ in range(3)])\n",
    "        self.heads_dropout = nn.Dropout(heads_dropout)\n",
    "        self.pff_dropout = nn.Dropout(pff_dropout)\n",
    "\n",
    "    def forward(self, o_lm1, encoder_l_output, self_attn_mask, cross_attn_mask):\n",
    "        '''\n",
    "        o_lm1 : last decoder layer activations. \n",
    "            shape (batch_size=b, out_len, d_model).\n",
    "        encoder_l_output : encoder output from at the same layer index. \n",
    "                       shape (batch_size=b, inp_len, d_model)\n",
    "        '''\n",
    "\n",
    "        # (b, out_len, d_model)\n",
    "        o_lm1_self_h, self_attn_wts = self.self_attn(o_lm1, o_lm1, self_attn_mask)\n",
    "        # (b, out_len, d_model)\n",
    "        o_lm1_self_h_norm = self.layer_norms[0](o_lm1 + self.heads_dropout(o_lm1_self_h))\n",
    "        # (b, out_len, d_model)\n",
    "        o_lm1_cross_h, cross_attn_wts = self.cross_attn(o_lm1_self_h_norm, encoder_l_output, cross_attn_mask)\n",
    "        # (b, out_len, d_model)\n",
    "        o_lm1_cross_h_norm = self.layer_norms[1](o_lm1_self_h_norm + self.heads_dropout(o_lm1_cross_h))\n",
    "        # (b, out_len, d_model)\n",
    "        o_lm1_ff = self.poswise_ff(o_lm1_cross_h_norm)\n",
    "        # (b, out_len, d_model)\n",
    "        o_l = self.layer_norms[2](o_lm1_cross_h_norm + self.pff_dropout(o_lm1_ff))\n",
    "        return o_l, self_attn_wts, cross_attn_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Depth 5\n",
    "# https://arxiv.org/pdf/1607.06450.pdf\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    '''Layer Normalization'''\n",
    "\n",
    "    def __init__(self, d_model, epsilon=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.gain = nn.Parameter(torch.ones(d_model))\n",
    "        self.bias = nn.Parameter(torch.zeros(d_model))\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Args:\n",
    "            x : shape (m, len, d_model)\n",
    "        Returns:\n",
    "            whitened_x : shape (m, len, d_model)\n",
    "        '''\n",
    "        # (m, len, 1)\n",
    "        mu = torch.mean(x, dim=-1, keepdim=True)\n",
    "        std = torch.std(x, dim=-1, keepdim=True)\n",
    "        # (m, len, d_model)\n",
    "        whitened_x = self.gain * (x - mu / (std + self.epsilon)) + self.bias\n",
    "        return whitened_x\n",
    "\n",
    "\n",
    "class Positiontwise_FF(nn.Module):\n",
    "    '''Pointwise FeedForward / Fat-RELU'''\n",
    "\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(Positiontwise_FF, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Args:\n",
    "            x : shape (m, len, d_model)\n",
    "        Returns:\n",
    "            shape (m, len, d_model)\n",
    "        '''\n",
    "        return self.linear2(F.relu(self.linear1(x)))\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    '''Multihead Attention'''\n",
    "\n",
    "    def __init__(self, d_model, h, attn_wt_dropout):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.h = h\n",
    "        self.d_model = d_model\n",
    "        # d_k, same as d_q, d_v\n",
    "        self.d_k = int(d_model / h)\n",
    "        \n",
    "\n",
    "        ############################################################\n",
    "        # simply use clone\n",
    "    \n",
    "        # shape (d_model, d_k * h = d_model)\n",
    "        projection = nn.Linear(d_model, d_model, bias=True)\n",
    "        # clone projection to become WQ, WK, WV, WO\n",
    "        self.projections_QKVO = nn.ModuleList([copy.deepcopy(projection) for _ in range(4)])\n",
    "        ############################################################\n",
    "        # # Untie only WQ\n",
    "\n",
    "        # # template for WQ, WK, WV, WO projection matrices\n",
    "        # # shape (d_model, d_k * h = d_model)\n",
    "        # make_projection = lambda: nn.Linear(d_model, d_model, bias=True)\n",
    "\n",
    "        # # shape (d_model, d_k * h = d_model)\n",
    "        # shared_projection = make_projection()\n",
    "\n",
    "        # # WQ independent, WKVO shared\n",
    "        # projections = (\n",
    "        #     [make_projection()] + [copy.deepcopy(shared_projection) for _ in range(3)]\n",
    "        # )\n",
    "        # self.projections_QKVO = nn.ModuleList(projections)\n",
    "\n",
    "        ############################################################\n",
    "#         # Untie WQ, WK, WV, WO\n",
    "        \n",
    "#         # template for WQ, WK, WV, WO projection matrices\n",
    "#         # shape (d_model, d_k * h = d_model)\n",
    "#         make_projection = lambda: nn.Linear(d_model, d_model, bias=True)\n",
    "#         # make WQ, WK, WV, WO\n",
    "#         self.projections_QKVO = nn.ModuleList([make_projection() for _ in range(4)])\n",
    "        ############################################################\n",
    "#        # initialize WO as zeros to start training w/ identity function\n",
    "#         self.projections_QKVO[3].weight.data = self.projections_QKVO[3].weight.data * 0.0\n",
    "#         self.projections_QKVO[3].bias.data = self.projections_QKVO[3].bias.data * 0.0\n",
    "        ############################################################       \n",
    "        \n",
    "        self.attn_wt_dropout = nn.Dropout(p=attn_wt_dropout)\n",
    "        \n",
    "\n",
    "    def forward(self, X, Y, mask):\n",
    "        '''\n",
    "        Args:\n",
    "            X : Attender. shape (batch_size=b, attender len=n, d_model)\n",
    "            Y : Attendee. shape (batch_size=b, attendee len=m, d_model)\n",
    "        Return:\n",
    "            attn_V : shape (b, n, h*d_k=d_model)\n",
    "        '''\n",
    "        b, n, d_model = X.shape\n",
    "\n",
    "        # Project X and Y to Q, K, V matrices\n",
    "        # Step 1 W(vals)\n",
    "        # XQ shape(b, n, d_k *h = d_model)\n",
    "        # YK shape(b, m, d_k *h = d_model)\n",
    "        # YV shape(b, m, d_k *h = d_model)\n",
    "        # Step 2 reshape()\n",
    "        # XQ shape(b, n, h, d_k)\n",
    "        # YK shape(b, m, h, d_k)\n",
    "        # YV shape(b, m, h, d_k)\n",
    "        # Step 3 swap axis with transpose()\n",
    "        # XQ shape(b, h, n, d_k)\n",
    "        # YK shape(b, h, m, d_k)\n",
    "        # YV shape(b, h, m, d_k)\n",
    "        XQ, YK, YV = [\n",
    "                      W(vals).reshape(b, -1, self.h, self.d_k)\n",
    "                      .transpose(1, 2) \n",
    "                      for (W, vals) in zip(self.projections_QKVO[:3], (X, Y, Y))]\n",
    "\n",
    "        # attention weighted values, attention weights\n",
    "        # shape (b, n, h, d_k), (b, h, n, m)\n",
    "        concat_V, attn = dotproduct_attention(\n",
    "            XQ, YK, YV, mask, self.attn_wt_dropout)\n",
    "        # shape (b, n, h*d_k=d_model)\n",
    "        concat_V = concat_V.reshape(b, n, -1)\n",
    "\n",
    "        # project by WO, shape (b, n, h*d_k=d_model)\n",
    "        attn_V = self.projections_QKVO[3](concat_V)\n",
    "   \n",
    "        return attn_V, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor([[[0., 1., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [1., 1., 0.]]])\n",
      "alpha\n",
      " tensor([[[[-1.0231,  0.0260,  0.2767],\n",
      "          [ 0.7859,  0.2193,  0.9244],\n",
      "          [-0.5686,  1.7561,  1.9875]],\n",
      "\n",
      "         [[-0.5513, -0.7215,  0.3740],\n",
      "          [ 0.9782,  1.1411, -0.4604],\n",
      "          [-0.0315,  0.7704, -0.9848]]]])\n",
      "mask_stack\n",
      " tensor([[[[0., 1., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [1., 1., 0.]],\n",
      "\n",
      "         [[0., 1., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [1., 1., 0.]]]])\n",
      "alpha_masked\n",
      " tensor([[[[-1.0231e+00, -1.0000e+04,  2.7667e-01],\n",
      "          [ 7.8594e-01, -1.0000e+04,  9.2435e-01],\n",
      "          [-1.0000e+04, -1.0000e+04,  1.9875e+00]],\n",
      "\n",
      "         [[-5.5126e-01, -1.0000e+04,  3.7404e-01],\n",
      "          [ 9.7823e-01, -1.0000e+04, -4.6042e-01],\n",
      "          [-1.0000e+04, -1.0000e+04, -9.8484e-01]]]])\n",
      "beta\n",
      " tensor([[[[0.2142, 0.0000, 0.7858],\n",
      "          [0.4655, 0.0000, 0.5345],\n",
      "          [0.0000, 0.0000, 1.0000]],\n",
      "\n",
      "         [[0.2839, 0.0000, 0.7161],\n",
      "          [0.8082, 0.0000, 0.1918],\n",
      "          [0.0000, 0.0000, 1.0000]]]])\n",
      "wt_V\n",
      " tensor([[[[ 0.0503,  1.3734,  1.3906,  1.1347, -1.4249],\n",
      "          [ 0.2252,  0.0178,  1.1088, -1.3340, -0.2037]],\n",
      "\n",
      "         [[ 0.3770,  1.4147,  0.6841,  0.8578, -1.6775],\n",
      "          [-0.3468, -1.9870,  0.6939, -1.2022,  0.5139]],\n",
      "\n",
      "         [[-0.2282,  1.3382,  1.9929,  1.3708, -1.2096],\n",
      "          [ 0.5349,  1.1031,  1.3334, -1.4053, -0.5922]]]])\n",
      "ref wt_V\n",
      " tensor([[[[ 0.0503,  1.3734,  1.3906,  1.1347, -1.4249],\n",
      "          [ 0.2252,  0.0178,  1.1088, -1.3340, -0.2037]],\n",
      "\n",
      "         [[ 0.3770,  1.4147,  0.6841,  0.8578, -1.6775],\n",
      "          [-0.3468, -1.9870,  0.6939, -1.2022,  0.5139]],\n",
      "\n",
      "         [[-0.2282,  1.3382,  1.9929,  1.3708, -1.2096],\n",
      "          [ 0.5349,  1.1031,  1.3334, -1.4053, -0.5922]]]])\n",
      "ref wt_V\n",
      " torch.Size([1, 2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "## Code Depth 6\n",
    "\n",
    "def dotproduct_attention(Q, K, V, mask, beta_dropout, debug=False):\n",
    "    '''\n",
    "    Q: shape(batch_size=b, num heads=h, attender len=n, d_k)\n",
    "    K: shape(batch_size=b, num heads=h, attendee len=m, d_k)\n",
    "    V: shape(batch_size=b, num heads=h, attendee len=m, d_k)\n",
    "    mask: shape(batch_size=b, n, m)\n",
    "    beta_dropout: nn.Dropout().apply module\n",
    "    '''\n",
    "    b, h, n, d_k = Q.shape\n",
    "    b, h, m, d_k = K.shape\n",
    "\n",
    "    # XQ shape(b, h, n, d_k) matmul YK.T shape(b, h, d_k, m)\n",
    "    # = alpha shape (b, h, n, m)\n",
    "    alpha = torch.matmul(Q, K.transpose(-1, -2))/ math.sqrt(d_k)\n",
    "\n",
    "    # Apply mask \n",
    "    # (b, h, n, m)\n",
    "    mask_stack = mask.unsqueeze(1).expand(-1, h, -1, -1)\n",
    "    alpha_masked = torch.masked_fill(alpha, mask_stack==1, -1e4)\n",
    "\n",
    "    # normalize across attendee len m\n",
    "    # (b, h, n, m)\n",
    "    beta = beta_dropout(torch.softmax(alpha_masked, dim=-1))\n",
    "\n",
    "    # beta shape(b, h, n, m) bmm YK.T shape(b, h, m, d_k) = shape (b, h, n, d_k)\n",
    "    # transpose to (b, n, h, d_k)\n",
    "    wt_V = torch.matmul(beta, V).transpose(1, 2)\n",
    "\n",
    "    if debug:\n",
    "        print('alpha\\n', alpha)\n",
    "        print('mask_stack\\n', mask_stack)\n",
    "        print('alpha_masked\\n', alpha_masked)\n",
    "        print('beta\\n', beta)\n",
    "        print('wt_V\\n', wt_V)\n",
    "        \n",
    "    return wt_V, beta\n",
    "\n",
    "\n",
    "def ref_attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 1, -1e9)\n",
    "    p_attn = torch.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "\n",
    "def test_attention(attn_fn):\n",
    "    torch.manual_seed(123)\n",
    "    b, h, n, m, d_k = 1, 2, 3, 3, 5\n",
    "    Q = torch.randn(b, h, n, d_k)\n",
    "    K = torch.randn(b, h, m, d_k)\n",
    "    V = torch.randn(b, h, m, d_k)\n",
    "\n",
    "    # print('Q\\n', Q)\n",
    "    # print('K\\n', K)\n",
    "    # print('V\\n', V)\n",
    "\n",
    "    mask = torch.zeros((b, n, m))\n",
    "    mask[:,:,1] = 1\n",
    "    mask[:,2,:1] = 1\n",
    "    print('input', mask)\n",
    "\n",
    "    my_wt_V = dotproduct_attention(Q, K, V, mask, nn.Dropout(0.0), debug=True)\n",
    "    ref_wt_V, ref_p_attn = ref_attention(Q, K, V, mask, nn.Dropout(0.0))\n",
    "  \n",
    "    print('ref wt_V\\n', ref_wt_V.transpose(1, 2))\n",
    "    print('ref wt_V\\n', ref_wt_V.shape)\n",
    "\n",
    "test_attention(dotproduct_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Attention:\n",
      "attender_mask_expanded\n",
      " tensor([[[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [1, 1, 1, 1]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [1, 1, 1, 1]]])\n",
      "attendee_mask_expanded\n",
      " tensor([[[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1]]])\n",
      "sum mask\n",
      " tensor([[[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [1, 1, 1, 1]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [1, 1, 1, 1]]], dtype=torch.int32)\n",
      "--------------------------------------\n",
      "Self Attention:\n",
      "future_mask\n",
      " tensor([[0, 1, 1, 1],\n",
      "        [0, 0, 1, 1],\n",
      "        [0, 0, 0, 1],\n",
      "        [0, 0, 0, 0]])\n",
      "attender_mask_expanded\n",
      " tensor([[[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [1, 1, 1, 1]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [1, 1, 1, 1]]])\n",
      "attendee_mask_expanded\n",
      " tensor([[[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1]]])\n",
      "sum mask\n",
      " tensor([[[0, 1, 1, 1],\n",
      "         [0, 0, 1, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [1, 1, 1, 1]],\n",
      "\n",
      "        [[0, 1, 1, 1],\n",
      "         [0, 0, 1, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 1, 1],\n",
      "         [0, 0, 1, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [1, 1, 1, 1]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "def make_attn_mask(attender_pads, attendee_pads, mask_forward=False, debug=False):\n",
    "    '''\n",
    "    Mask away attendee positions from attender.\n",
    "    Args:\n",
    "        attender_pads: shape(batch_size=b, attender len=n). 1s are pads.\n",
    "        attendee_pads: shape(batch_size=b, attender len=m). 1s are pads.\n",
    "    Return:\n",
    "        attn_mask: shape(b, n, m)\n",
    "    '''\n",
    "\n",
    "    b, n = attender_pads.shape\n",
    "    b, m = attendee_pads.shape\n",
    "\n",
    "    if mask_forward: \n",
    "        assert n == m\n",
    "        # shape (n, m)\n",
    "        try:\n",
    "            future_mask = torch.from_numpy(\n",
    "                np.triu(np.ones((n, m)), k=1)).type_as(attender_pads)\n",
    "        except:\n",
    "            import pdb; pdb.set_trace()\n",
    "        # shape (b, n, m)\n",
    "        future_mask_expanded = future_mask.unsqueeze(0).expand(b, -1, -1)\n",
    "\n",
    "    # shape(b, n, m)\n",
    "    attender_mask_expanded = attender_pads.unsqueeze(-1).expand(-1, -1, m)\n",
    "    # shape(b, n, m)\n",
    "    attendee_mask_expanded = attendee_pads.unsqueeze(1).expand(-1, n, -1)\n",
    "\n",
    "    # shape(b, n, m)\n",
    "    if mask_forward: \n",
    "        sum_mask = attender_mask_expanded + attendee_mask_expanded + future_mask\n",
    "    else:\n",
    "        sum_mask = attender_mask_expanded + attendee_mask_expanded\n",
    "    sum_mask = (sum_mask > 0).type(torch.int)\n",
    "\n",
    "    if debug:\n",
    "        if mask_forward:\n",
    "            print('future_mask\\n',future_mask)\n",
    "        print('attender_mask_expanded\\n',attender_mask_expanded)\n",
    "        print('attendee_mask_expanded\\n',attendee_mask_expanded)\n",
    "        print('sum mask\\n', sum_mask)\n",
    "\n",
    "    return sum_mask\n",
    "\n",
    "\n",
    "def test_make_attn_mask():\n",
    "    #   attender_pads = torch.tensor([[0,0,0,1,1], [0,0,1,1,1], [0,0,0,0,0]])\n",
    "    attender_pads = torch.tensor([[0,0,0,1], [0,0,0,0], [0,0,0,1]])\n",
    "    attendee_pads = torch.tensor([[0,0,0,1], [0,0,0,0], [0,0,0,1]])\n",
    "    print('Cross Attention:')\n",
    "    make_attn_mask(attender_pads, attendee_pads, mask_forward=False, debug=True)\n",
    "    print('--------------------------------------')\n",
    "    print('Self Attention:')\n",
    "    make_attn_mask(attender_pads, attender_pads, mask_forward=True, debug=True)\n",
    "\n",
    "\n",
    "test_make_attn_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(68.0340)\n",
      "tensor(68.0340)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/playground/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "class LabelSmoothedLoss(nn.Module):\n",
    "    '''\n",
    "    KL divergence Loss with Label Smoothing and Temperature scaling\n",
    "    '''\n",
    "\n",
    "    def __init__(self, K, padding_idx, smoothing_const=0.0, temperature_const=1.0):\n",
    "        super(LabelSmoothedLoss, self).__init__()\n",
    "        self.smoothing_const = smoothing_const\n",
    "        self.temperature_const = temperature_const\n",
    "        self.K = K\n",
    "        self.padding_idx = padding_idx\n",
    "        self.KLdiv_criterion = nn.KLDivLoss(reduction='sum')\n",
    "        self.logprob = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "\n",
    "    def forward(self, logits, labels, debug=False):\n",
    "        '''\n",
    "        logits: shape (batch_size=b, output_len=m, vocab_size=K)\n",
    "        labels: shape (batch_size=b, output_len=m)\n",
    "        '''\n",
    "        b, m, K = logits.shape\n",
    "\n",
    "        # Temperature Scaling\n",
    "        # shape (b*m, K)\n",
    "        scaled_logits = (logits / self.temperature_const).reshape(-1, K)\n",
    "        pred_logprobs = self.logprob(scaled_logits)\n",
    "\n",
    "        # Expand Labels to one-hot, Smooth the values\n",
    "        gt_probs_smoothed = torch.full(\n",
    "            size=(b*m, K), \n",
    "            # fill_value=self.smoothing_const / (K - 1), # more mathematicaly correct\n",
    "            fill_value=self.smoothing_const / (K - 2) #minus true and padding\n",
    "        ).type_as(logits)\n",
    "\n",
    "        gt_probs_smoothed = gt_probs_smoothed.scatter(\n",
    "            dim=-1, \n",
    "            index=labels.reshape(-1, 1), \n",
    "            value=(1. - self.smoothing_const),\n",
    "            # value=(1. - self.smoothing_const) + (self.smoothing_const / (K - 1)) # more mathematicaly correct\n",
    "        )\n",
    "        # Zero out padding idx\n",
    "        # shape (b*m, K)\n",
    "        gt_probs_smoothed[:, self.padding_idx] = 0.\n",
    "    \n",
    "        # Apply mask (e.g. if end of context is padded)\n",
    "        # shape (b*m, 1)\n",
    "        mask_ctx_pos = torch.nonzero(torch.flatten(labels) == self.padding_idx)\n",
    "        if mask_ctx_pos.dim() > 0:\n",
    "            # zero out rows for padded context positions\n",
    "            # e.g. word at position 10 is a pad, we zero out all probs for row 10\n",
    "            gt_probs_smoothed.index_fill_(\n",
    "                dim=0, index=mask_ctx_pos.squeeze(), value=0.0)\n",
    "\n",
    "        if debug:\n",
    "            print(scaled_logits)\n",
    "            print(labels_onehot)\n",
    "            print(mask_ctx_pos)\n",
    "        \n",
    "        try:\n",
    "            assert torch.all(\n",
    "                torch.logical_or(\n",
    "                    torch.logical_and(\n",
    "                        # sum of probs == 1\n",
    "                        torch.greater(torch.sum(gt_probs_smoothed, dim=-1), 0.999),\n",
    "                        torch.less(torch.sum(gt_probs_smoothed, dim=-1), 1.001) \n",
    "                    ),\n",
    "                    # except padded positions in context\n",
    "                    torch.eq(torch.sum(gt_probs_smoothed, dim=-1), 0.)\n",
    "                )\n",
    "            )\n",
    "        except:\n",
    "            import pdb; pdb.set_trace()\n",
    "\n",
    "        return self.KLdiv_criterion(input=pred_logprobs, target=gt_probs_smoothed)\n",
    "\n",
    "\n",
    "# Only Use for verification\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))\n",
    "\n",
    "\n",
    "def test_loss_function(myLoss, refLoss, smoothing_const, temperature_const):\n",
    "    K = 3\n",
    "    padding_idx = 0\n",
    "\n",
    "    torch.manual_seed(123)\n",
    "    myKL = myLoss(K, padding_idx, smoothing_const, temperature_const)\n",
    "    refKL = refLoss(K, padding_idx, smoothing_const)\n",
    "\n",
    "    labels = torch.tensor([[1, 1, 1, 0], [2, 2, 1, 1], [1, 1, 2, 1], [2, 1, 1, 0], [2, 1, 1, 2]])\n",
    "    inputs = torch.randn(5, 4, 3) * 4\n",
    "\n",
    "    ref_loss = refKL(F.log_softmax(inputs, dim=-1).reshape(-1, 3), torch.flatten(labels))\n",
    "    my_loss = myKL(inputs, labels )\n",
    "    #   if temperature_const == 1.0:\n",
    "    #     assert ref_loss == my_loss\n",
    "    print(ref_loss, )\n",
    "    print(my_loss)\n",
    "\n",
    "test_loss_function(myLoss=LabelSmoothedLoss, refLoss=LabelSmoothing, smoothing_const=0.1, temperature_const=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LRScheduledAdam(Optimizer):\n",
    "    \"\"\"\n",
    "    Implements Adam algorithm with learning rate schedule.\n",
    "    Modified based on hugging face implementation:\n",
    "    https://huggingface.co/transformers/_modules/transformers/optimization.html#AdamW\n",
    "\n",
    "    Parameters:\n",
    "        params (:obj:`Iterable[torch.nn.parameter.Parameter]`):\n",
    "            Iterable of parameters to optimize or dictionaries defining parameter groups.\n",
    "        d_model (:obj:`int`):\n",
    "            Dimension of embedding vector.\n",
    "        warmup_steps (:obj:`int`):\n",
    "            Steps for warmup before learning rate peaks.\n",
    "        lr (:obj:`float`, `optional`, defaults to 0.):\n",
    "            The learning rate to use.\n",
    "        betas (:obj:`Tuple[float,float]`, `optional`, defaults to (0.9, 0.999)):\n",
    "            Adam's betas parameters (b1, b2).\n",
    "        eps (:obj:`float`, `optional`, defaults to 1e-6):\n",
    "            Adam's epsilon for numerical stability.\n",
    "        weight_decay (:obj:`float`, `optional`, defaults to 0):\n",
    "            Decoupled weight decay to apply.\n",
    "        correct_bias (:obj:`bool`, `optional`, defaults to `True`):\n",
    "            Whether ot not to correct bias in Adam (for instance, in Bert TF repository they use :obj:`False`).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        params: Iterable[torch.nn.parameter.Parameter],\n",
    "        d_model: int,\n",
    "        warmup_steps: int,\n",
    "        lr: float = 0.,\n",
    "        betas: Tuple[float, float] = (0.9, 0.98),\n",
    "        eps: float = 1e-9,\n",
    "        correct_bias: bool = True,\n",
    "    ):\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {} - should be >= 0.0\".format(lr))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter: {} - should be in [0.0, 1.0[\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter: {} - should be in [0.0, 1.0[\".format(betas[1]))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {} - should be >= 0.0\".format(eps))\n",
    "        defaults = dict(\n",
    "            lr=lr, betas=betas, eps=eps, correct_bias=correct_bias)\n",
    "        super().__init__(params, defaults)\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def calc_step_size(self, step_num):\n",
    "        '''udpate lr'''\n",
    "        return (\n",
    "            self.d_model**(-0.5) * min(step_num**(-0.5), step_num * self.warmup_steps**(-1.5))\n",
    "        )\n",
    "\n",
    "    def step(self, closure: Callable = None):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "\n",
    "        Arguments:\n",
    "            closure (:obj:`Callable`, `optional`): A closure that reevaluates the model and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError(\"Adam does not support sparse gradients, please consider SparseAdam instead\")\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 0:\n",
    "                    state[\"step\"] = 0\n",
    "                    # Exponential moving average of gradient values\n",
    "                    state[\"exp_avg\"] = torch.zeros_like(p.data)\n",
    "                    # Exponential moving average of squared gradient values\n",
    "                    state[\"exp_avg_sq\"] = torch.zeros_like(p.data)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state[\"exp_avg\"], state[\"exp_avg_sq\"]\n",
    "                beta1, beta2 = group[\"betas\"]\n",
    "\n",
    "                state[\"step\"] += 1\n",
    "\n",
    "                # Decay the first and second moment running average coefficient\n",
    "                # In-place operations to update the averages at the same time\n",
    "                exp_avg.mul_(beta1).add_(grad, alpha=1.0 - beta1)\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1.0 - beta2)\n",
    "                denom = exp_avg_sq.sqrt().add_(group[\"eps\"])\n",
    "\n",
    "                group[\"lr\"] = self.calc_step_size(state[\"step\"])\n",
    "                step_size = group[\"lr\"]\n",
    "                if group[\"correct_bias\"]:  # No bias correction for Bert\n",
    "                    bias_correction1 = 1.0 - beta1 ** state[\"step\"]\n",
    "                    bias_correction2 = 1.0 - beta2 ** state[\"step\"]\n",
    "                    step_size = step_size * math.sqrt(bias_correction2) / bias_correction1\n",
    "\n",
    "                p.data.addcdiv_(exp_avg, denom, value=-step_size)\n",
    "        return loss\n",
    "\n",
    "def plot_lr(myOpt):\n",
    "    model = nn.Linear(2,3)\n",
    "    opts = [myOpt(model.parameters(), 512, 4000), \n",
    "            myOpt(model.parameters(), 512, 8000),\n",
    "            myOpt(model.parameters(), 256, 4000)]\n",
    "    plt.plot(np.arange(1, 20000), [[opt.calc_step_size(i) for opt in opts] for i in range(1, 20000)])\n",
    "    plt.legend([\"512:4000\", \"512:8000\", \"256:4000\"])\n",
    "\n",
    "plot_lr(LRScheduledAdam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode_sequence(model, X, start_idx, pad_idx, max_len):\n",
    "    '''\n",
    "    Greedy Decoding\n",
    "    X : a sequence of input symbols. shape(batch_size=b, inp_len)\n",
    "    start_idx: int.\n",
    "    pad_idx: int.\n",
    "    max_len: int. Maximum context length for generation. Include <SOS> and <EOS>\n",
    "    '''\n",
    "\n",
    "    b, inp_len = X.shape\n",
    "    inp_pads = (X == pad_idx).int()\n",
    "\n",
    "    # encode inputs\n",
    "    # shape (b, inp_len, d_model)\n",
    "    encoded_memory = model.encode(X, inp_pads)\n",
    " \n",
    "    # shape (b, max_len) e.g. (b, 10)\n",
    "    Y = torch.ones(b, max_len).type_as(X) * pad_idx\n",
    "    Y[:,0] = start_idx\n",
    "    # shape (b, max_len)\n",
    "    out_pads = (Y == pad_idx).int()\n",
    "  \n",
    "    # generate one token at a time\n",
    "    for t in range(1, max_len): # (1 to 9)\n",
    "\n",
    "        # shape (b, t, d_model)\n",
    "        decoder_output = model.decode(encoded_memory, Y[:, :t], inp_pads, out_pads[:, :t])\n",
    "\n",
    "        # shape (b, t, V)\n",
    "        decoded_logits = model.classifier(decoder_output)\n",
    "        # decoded_probs = torch.softmax(decoded_logits, dim=-1)\n",
    "    \n",
    "        # shape (b,), (b,)\n",
    "        max_prob, max_idx = torch.max(decoded_logits[:, -1, :], dim=-1)\n",
    "    \n",
    "        # update Y, out_pads for next timestep\n",
    "        Y[:, t] = max_idx\n",
    "        out_pads[:, t] = (max_idx == pad_idx).int()\n",
    "\n",
    "    # shape (b, max_len)\n",
    "    # (1 to 9)\n",
    "    return Y[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiclass_accuracy(start_idx, pad_idx, pred, labels):\n",
    "    '''\n",
    "    pred: shape (batch_size, max_len)\n",
    "    labels: shape (batch_size, max_len) \n",
    "    '''\n",
    "    assert not start_idx in labels, '<GO> should not be evaluated'\n",
    "\n",
    "    mask = 1 - (labels == pad_idx).int() # 0 means padded\n",
    "    tot_not_masked = torch.sum(mask)\n",
    "\n",
    "    same = (pred == labels).int() * mask\n",
    "    tot_correct = torch.sum(same)\n",
    "\n",
    "    return tot_correct * 1.0 / tot_not_masked\n",
    "\n",
    "# 4/6\n",
    "multiclass_accuracy(1, 0, torch.tensor([[2,2,0,0],[7,8,7,0]]), torch.tensor([[2,2,0,4],[7,8,9,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Lightning Module\n",
    "# https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=UIXLW8CO-W8w\n",
    "\n",
    "class Transformer(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, hparams):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.hparams = hparams\n",
    "        \n",
    "        self.encdec_model = construct_full_model(hparams)\n",
    "        \n",
    "        self.loss_criterion = LabelSmoothedLoss(\n",
    "            K=hparams['vocab_size'],\n",
    "            padding_idx=hparams['padding_idx'],\n",
    "            smoothing_const=hparams['smoothing_const'],\n",
    "            temperature_const=hparams['temperature_const']\n",
    "        )\n",
    "\n",
    "        self.accuracy = partial(\n",
    "            multiclass_accuracy, hparams['start_idx'], hparams['padding_idx'])\n",
    "    \n",
    "    def log_metrics(self, metrics_dict):\n",
    "        for k, v in metrics_dict.items():\n",
    "            self.log(k, v)\n",
    "\n",
    "    def generate_sequence(self, X, start_idx, pad_idx, max_len):\n",
    "        # shape (b, max_len)\n",
    "        Y = greedy_decode_sequence(self.encdec_model, X, start_idx, pad_idx, max_len)\n",
    "        return Y\n",
    "\n",
    "    def get_max_memory_alloc(self):\n",
    "        devices_max_memory_alloc = {}\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            device = torch.device(f'cuda:{i}')\n",
    "            devices_max_memory_alloc[device] = torch.cuda.max_memory_allocated(device) / 1e6\n",
    "            torch.cuda.reset_max_memory_allocated(device)\n",
    "        return devices_max_memory_alloc\n",
    "    \n",
    "    def forward(self, X, Y, student_force_acc=False):\n",
    "        '''\n",
    "        X : (b, inp_len)\n",
    "        Y : (b, out_len)\n",
    "        '''\n",
    "\n",
    "        import pdb; pdb.set_trace()\n",
    "        # fwd\n",
    "        # inp X[:,:]: tensor([<go>, ... , <stop>, pad, pad, pad ...])\n",
    "        # out Y[:, :-1]: tensor([<go>, ... , <stop>, pad, pad ...])\n",
    "        logits = self.encdec_model(X[:,:], Y[:, :-1])\n",
    "        \n",
    "        import pdb; pdb.set_trace()\n",
    "        # loss\n",
    "        # target Y[:, 1:]: tensor([ ... , <stop>, pad, pad ...])\n",
    "        loss = self.loss_criterion(logits, Y[:, 1:])\n",
    "\n",
    "        import pdb; pdb.set_trace()\n",
    "        # acc\n",
    "        if student_force_acc:\n",
    "            # doesn't include <go>\n",
    "            y_hat = self.generate_sequence(\n",
    "                X, \n",
    "                hparams['start_idx'], \n",
    "                hparams['padding_idx'], \n",
    "                hparams['max_len'])         \n",
    "        else:\n",
    "            # doesn't include <go>\n",
    "            _, y_hat = torch.max(logits, dim=-1)\n",
    "        \n",
    "        import pdb; pdb.set_trace()\n",
    "        try:\n",
    "            acc = self.accuracy(y_hat, Y[:, 1:])\n",
    "        except:\n",
    "            import pdb; pdb.set_trace()\n",
    "\n",
    "        import pdb; pdb.set_trace()\n",
    "        return loss, acc, y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # (b, inp_len), (b, 1 GO + out_len) \n",
    "        X, Y = batch     \n",
    "        loss, acc, y_hat = self(X, Y)\n",
    "        # logs\n",
    "        step_metrics = {'train_loss': loss, 'train_acc':acc}\n",
    "        self.log_metrics(step_metrics)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # check if tensors are init at 16-bit here\n",
    "#         import pdb; pdb.set_trace()\n",
    "\n",
    "        X, Y = batch\n",
    "        \n",
    "        loss, acc, y_hat = self(X, Y, student_force_acc=True)\n",
    "        \n",
    "        # print sample\n",
    "        print('X:',X[0], '\\nY:',Y[0] ,'\\ninp X', X[0, :], '\\nout Y[:, :-1]', Y[0, :-1], \n",
    "              '\\ntgt Y', Y[0, 1:],'\\ny_hat', y_hat[0])\n",
    "        \n",
    "        # log\n",
    "        step_metrics = {'val_loss': loss, 'val_acc': acc}\n",
    "        devices_max_memory_alloc = self.get_max_memory_alloc()\n",
    "        for device, val in devices_max_memory_alloc.items():\n",
    "            step_metrics[f'step_max_memory_alloc_cuda:{device}'] = val\n",
    "        self.log_metrics(step_metrics)\n",
    "        return step_metrics\n",
    "    \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        X, Y = batch\n",
    "        loss, acc, y_hat = self(X, Y, student_force_acc=True)\n",
    "        # log\n",
    "        step_metrics = {'test_loss': loss, 'test_acc': acc}\n",
    "        # print('X:',X[0], '\\nY:',Y[0], '\\ny_hat', y_hat[0])\n",
    "        self.log_metrics(step_metrics)\n",
    "        return step_metrics\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        # log metrics\n",
    "        epoch_metrics = {\n",
    "            'avg_val_loss': avg_loss, \n",
    "            'avg_val_acc': avg_acc,\n",
    "            'encoder_pff_wt': self.encdec_model.encoder.encoder_layers[0].poswise_ff.linear1.weight[0,0],\n",
    "            'decoder_pff_wt': self.encdec_model.decoder.decoder_layers[0].poswise_ff.linear1.weight[0,0]}\n",
    "        self.log_metrics(epoch_metrics)\n",
    "        return epoch_metrics\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n",
    "        # log\n",
    "        epoch_metrics = {'avg_test_loss': avg_loss, 'avg_test_acc': avg_acc}\n",
    "        self.log_metrics(epoch_metrics)\n",
    "        return epoch_metrics\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        opt = LRScheduledAdam(\n",
    "            params=self.encdec_model.parameters(),\n",
    "            d_model=self.hparams['d_model'], \n",
    "            warmup_steps=self.hparams['warmup_steps'],\n",
    "            lr=0.,\n",
    "            betas=(\n",
    "                self.hparams['adam_beta1'], self.hparams['adam_beta2']),\n",
    "            eps=self.hparams['adam_epsilon'],\n",
    "            correct_bias=True\n",
    "        )\n",
    "        # opt = torch.optim.SGD(self.encdec_model.parameters(), lr=0.001, momentum=0.9)\n",
    "        # opt = AdamW(\n",
    "        #     params=self.encdec_model.parameters(),\n",
    "        #     lr=0.,\n",
    "        #     betas=(\n",
    "        #         self.hparams['adam_beta1'], self.hparams['adam_beta2']),\n",
    "        #     eps=self.hparams['adam_epsilon'],\n",
    "        # )\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataloaders\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "    '''Toy Dataset. Input copying task.'''\n",
    "\n",
    "    def __init__(self, V=20, seed=0, context_len=6, tot_size=1000):\n",
    "        super(ToyDataset, self).__init__()\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        \n",
    "#         #############################################################\n",
    "#         # completely random series\n",
    "#         self.X = np.random.randint(3, V, size=(tot_size, context_len)) # [3, 49]\n",
    "#         self.X[:, 0] = 1 # <SOS>\n",
    "#         self.X[:, -1] = 2 # <EOS>\n",
    "#         self.Y = self.X[:,:].copy()\n",
    "        #############################################################\n",
    "        # reverse order\n",
    "        self.X = np.random.randint(3, V, size=(tot_size, context_len)) # [3, 49]\n",
    "        self.X[:, 0] = 1 # <SOS>\n",
    "        self.X[:, -1] = 2 # <EOS>\n",
    "        self.Y = self.X[:,::-1].copy()        \n",
    "        self.Y[:, 0] = 1 # <SOS>\n",
    "        self.Y[:, -1] = 2 # <EOS>  \n",
    "        #############################################################\n",
    "#         # + 1 series\n",
    "#         self.X = np.empty((tot_size, context_len))\n",
    "#         self.X[:, 1] = np.random.randint(3, V - (context_len - 3), size=(tot_size, ))\n",
    "#         for i in range(2, context_len):\n",
    "#             self.X[:, i] = self.X[:, i-1] + 1\n",
    "#         self.X[:, 0] = 1 # <SOS>\n",
    "#         self.X[:, -1] = 2 # <EOS>\n",
    "#         self.Y = self.X[:,:].copy()   \n",
    "#         #############################################################\n",
    "#         # sum of current X + last X\n",
    "#         self.X = np.empty((tot_size, context_len))\n",
    "#         self.X[:, 1:context_len] = np.random.randint(3, V//2+1, size=(tot_size,context_len-1))        \n",
    "#         self.X[:, 0] = 1 # <SOS>\n",
    "#         self.X[:, -1] = 2 # <EOS>\n",
    "#         self.Y = np.empty((tot_size, context_len))\n",
    "#         for i in range(1, context_len):\n",
    "#             self.Y[:, i] = self.X[:, i-1] + self.X[:, i]\n",
    "#         self.Y[:, 0] = 1 # <SOS>\n",
    "#         self.Y[:, -1] = 2 # <EOS>          \n",
    "#         #############################################################\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.X[idx, :]).long()\n",
    "        y = torch.from_numpy(self.Y[idx, :]).long()\n",
    "        return x, y\n",
    "\n",
    "toy_dataset = ToyDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samples of datasets\n",
    "\n",
    "## replicate random\n",
    "```\n",
    "X\n",
    "(tensor([[ 1, 18,  3,  6,  6,  2],\n",
    "         [ 1,  7,  9, 15,  4,  2],\n",
    "         [ 1, 17,  8, 16, 11,  2],\n",
    "         [ 1,  8, 18, 18,  3,  2],\n",
    "         [ 1, 10,  3,  4, 12,  2],\n",
    "         [ 1,  6, 14,  5,  3,  2],\n",
    "         [ 1,  8,  9, 11, 18,  2],\n",
    "         [ 1, 13,  4,  4, 10,  2],\n",
    "         [ 1,  9, 14, 17,  3,  2],\n",
    "         [ 1, 15, 13, 14,  7,  2]]),\n",
    "Y\n",
    " tensor([[ 1, 18,  3,  6,  6,  2],\n",
    "         [ 1,  7,  9, 15,  4,  2],\n",
    "         [ 1, 17,  8, 16, 11,  2],\n",
    "         [ 1,  8, 18, 18,  3,  2],\n",
    "         [ 1, 10,  3,  4, 12,  2],\n",
    "         [ 1,  6, 14,  5,  3,  2],\n",
    "         [ 1,  8,  9, 11, 18,  2],\n",
    "         [ 1, 13,  4,  4, 10,  2],\n",
    "         [ 1,  9, 14, 17,  3,  2],\n",
    "         [ 1, 15, 13, 14,  7,  2]]))\n",
    "```\n",
    "\n",
    "\n",
    "## reversed random\n",
    "```\n",
    "(tensor([[ 1, 18,  3,  6,  6,  2],\n",
    "         [ 1,  7,  9, 15,  4,  2],\n",
    "         [ 1, 17,  8, 16, 11,  2],\n",
    "         [ 1,  8, 18, 18,  3,  2],\n",
    "         [ 1, 10,  3,  4, 12,  2],\n",
    "         [ 1,  6, 14,  5,  3,  2],\n",
    "         [ 1,  8,  9, 11, 18,  2],\n",
    "         [ 1, 13,  4,  4, 10,  2],\n",
    "         [ 1,  9, 14, 17,  3,  2],\n",
    "         [ 1, 15, 13, 14,  7,  2]]),\n",
    " tensor([[ 1,  6,  6,  3, 18,  2],\n",
    "         [ 1,  4, 15,  9,  7,  2],\n",
    "         [ 1, 11, 16,  8, 17,  2],\n",
    "         [ 1,  3, 18, 18,  8,  2],\n",
    "         [ 1, 12,  4,  3, 10,  2],\n",
    "         [ 1,  3,  5, 14,  6,  2],\n",
    "         [ 1, 18, 11,  9,  8,  2],\n",
    "         [ 1, 10,  4,  4, 13,  2],\n",
    "         [ 1,  3, 17, 14,  9,  2],\n",
    "         [ 1,  7, 14, 13, 15,  2]]))\n",
    "```\n",
    "\n",
    "\n",
    "## autoregressive +1 series\n",
    "```\n",
    "X\n",
    "(tensor([[ 1, 15, 16, 17, 18,  2],\n",
    "         [ 1,  8,  9, 10, 11,  2],\n",
    "         [ 1,  3,  4,  5,  6,  2],\n",
    "         [ 1,  6,  7,  8,  9,  2],\n",
    "         [ 1, 14, 15, 16, 17,  2],\n",
    "         [ 1,  6,  7,  8,  9,  2],\n",
    "         [ 1, 10, 11, 12, 13,  2],\n",
    "         [ 1, 12, 13, 14, 15,  2],\n",
    "         [ 1,  6,  7,  8,  9,  2],\n",
    "         [ 1,  8,  9, 10, 11,  2]]),\n",
    "Y\n",
    " tensor([[ 1, 15, 16, 17, 18,  2],\n",
    "         [ 1,  8,  9, 10, 11,  2],\n",
    "         [ 1,  3,  4,  5,  6,  2],\n",
    "         [ 1,  6,  7,  8,  9,  2],\n",
    "         [ 1, 14, 15, 16, 17,  2],\n",
    "         [ 1,  6,  7,  8,  9,  2],\n",
    "         [ 1, 10, 11, 12, 13,  2],\n",
    "         [ 1, 12, 13, 14, 15,  2],\n",
    "         [ 1,  6,  7,  8,  9,  2],\n",
    "         [ 1,  8,  9, 10, 11,  2]]))\n",
    "```\n",
    "\n",
    "\n",
    "## current of X + last of X series\n",
    "```\n",
    "X\n",
    "(tensor([[ 1,  7, 10,  8,  3,  2],\n",
    "         [ 1,  6,  6, 10,  4,  2],\n",
    "         [ 1,  8,  5,  7, 10,  2],\n",
    "         [ 1,  3,  3,  7,  5,  2],\n",
    "         [ 1,  9, 10, 10,  9,  2],\n",
    "         [ 1,  4,  8,  4,  8,  2],\n",
    "         [ 1,  4,  7,  6,  3,  2],\n",
    "         [ 1,  8,  9, 10, 10,  2],\n",
    "         [ 1,  5,  6,  3,  4,  2],\n",
    "         [ 1,  8,  6,  6,  9,  2]]),\n",
    "Y\n",
    " tensor([[ 1,  8, 17, 18, 11,  2],\n",
    "         [ 1,  7, 12, 16, 14,  2],\n",
    "         [ 1,  9, 13, 12, 17,  2],\n",
    "         [ 1,  4,  6, 10, 12,  2],\n",
    "         [ 1, 10, 19, 20, 19,  2],\n",
    "         [ 1,  5, 12, 12, 12,  2],\n",
    "         [ 1,  5, 11, 13,  9,  2],\n",
    "         [ 1,  9, 17, 19, 20,  2],\n",
    "         [ 1,  6, 11,  9,  7,  2],\n",
    "         [ 1,  9, 14, 12, 15,  2]]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataModule(pl.LightningDataModule):\n",
    "    # https://wandb.ai/cayush/pytorchlightning/reports/Use-Pytorch-Lightning-with-Weights-Biases--Vmlldzo2NjQ1Mw\n",
    "\n",
    "    def __init__(self, batch_size, V, seed, context_len, tot_size):\n",
    "        super().__init__()\n",
    "        self.batch_size=batch_size\n",
    "        self.V = V\n",
    "        self.seed = seed\n",
    "        self.context_len = context_len\n",
    "        self.tot_size = tot_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage in None:\n",
    "            self.toy_train = ToyDataset(\n",
    "                V=self.V, seed=self.seed, \n",
    "                context_len=self.context_len, tot_size=self.tot_size)\n",
    "            self.toy_val = self.toy_train            \n",
    "            # self.toy_val = ToyDataset(\n",
    "            #     V=self.V, seed=42, \n",
    "            #     context_len=self.context_len, tot_size=self.batch_size*2) \n",
    "        if stage == 'test' or stage is None:\n",
    "            self.toy_test = self.toy_train\n",
    "            # self.toy_test = ToyDataset(\n",
    "            #     V=self.V, seed=41, \n",
    "            #     context_len=self.context_len, tot_size=self.batch_size*2)\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(self.toy_train, batch_size=self.batch_size, shuffle=False)\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = DataLoader(self.toy_val, batch_size=self.batch_size, shuffle=False)\n",
    "        return val_loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_loader = DataLoader(self.toy_test, batch_size=self.batch_size, shuffle=False)\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate datasets\n",
    "\n",
    "# load data and vocab\n",
    "polyexp_data_p = '../data/PolynomialExpansion/pp.json'\n",
    "polyexp_vocab_p = '../data/PolynomialExpansion/pp.vocab'\n",
    "\n",
    "with open(polyexp_data_p, 'r') as f:\n",
    "    polyexp_jsondata = json.load(f)\n",
    "\n",
    "polyexp_vocab = torch.load(polyexp_vocab_p)\n",
    "polyexp_vocab.word2index('<<go>>', train=True)\n",
    "\n",
    "\n",
    "class PolynomialExpansionDataset(Dataset):\n",
    "    '''olynomial Expansion Dataset.'''\n",
    "\n",
    "    def __init__(self, data, split, pad_idx, stop_idx, start_idx):\n",
    "        super().__init__()\n",
    "        self.split = split\n",
    "        # doesn't inlcude any <<go>>, <<stop>> or <<pad>>\n",
    "        self.X = data[split]['factors']\n",
    "        self.Y = data[split]['expansions']\n",
    "        self.pad_idx = pad_idx\n",
    "        self.stop_idx = stop_idx\n",
    "        self.start_idx = start_idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor([self.start_idx] + self.X[idx] + [self.stop_idx]).long()\n",
    "        y = torch.tensor([self.start_idx] + self.Y[idx] + [self.stop_idx]).long()\n",
    "        return x, y\n",
    "\n",
    "polyexp_dataset = PolynomialExpansionDataset(polyexp_jsondata, 'train', \n",
    "                                             pad_idx=0, stop_idx=1, start_idx=30)\n",
    "\n",
    "# for i in range(5):\n",
    "#     samp_x, samp_y = polyexp_dataset[i]\n",
    "#     print('X:\\n', ''.join(polyexp_vocab.index2word(samp_x.tolist())))\n",
    "#     print('Y:\\n', ''.join(polyexp_vocab.index2word(samp_y.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialExpansionDataModule(pl.LightningDataModule):\n",
    "    # https://wandb.ai/cayush/pytorchlightning/reports/Use-Pytorch-Lightning-with-Weights-Biases--Vmlldzo2NjQ1Mw\n",
    "\n",
    "    def __init__(self, batch_size, data, pad_idx, stop_idx, start_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.data = data\n",
    "        self.pad_idx = pad_idx\n",
    "        self.stop_idx = stop_idx\n",
    "        self.start_idx = start_idx\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage in None:\n",
    "            self.toy_train = PolynomialExpansionDataset(\n",
    "                self.data, 'train', self.pad_idx, self.stop_idx, self.start_idx\n",
    "            )\n",
    "            self.toy_val = self.toy_train            \n",
    "        if stage == 'test' or stage is None:\n",
    "            self.toy_test = self.toy_train\n",
    "    \n",
    "    def pad_collate(self, batch):\n",
    "        '''pad sequences in a batch to have the same length'''\n",
    "        (xx, yy) = zip(*batch)\n",
    "        x_lens = [len(x) for x in xx]\n",
    "        y_lens = [len(y) for y in yy]\n",
    "        xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "        yy_pad = pad_sequence(yy, batch_first=True, padding_value=0)\n",
    "#         return xx_pad, yy_pad, x_lens, y_lens\n",
    "        return xx_pad, yy_pad\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(\n",
    "            self.toy_train, batch_size=self.batch_size, shuffle=False, collate_fn=self.pad_collate)\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = DataLoader(\n",
    "            self.toy_val, batch_size=self.batch_size, shuffle=False, collate_fn=self.pad_collate)\n",
    "        return val_loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_loader = DataLoader(\n",
    "            self.toy_test, batch_size=self.batch_size, shuffle=False, collate_fn=self.pad_collate)\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name                                                                | Type               | Params\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "0  | encdec_model                                                        | EncoderDecoder     | 14 M  \n",
      "1  | encdec_model.encoder                                                | Encoder            | 6 M   \n",
      "2  | encdec_model.encoder.encoder_layers                                 | ModuleList         | 6 M   \n",
      "3  | encdec_model.encoder.encoder_layers.0                               | EncoderLayer       | 3 M   \n",
      "4  | encdec_model.encoder.encoder_layers.0.poswise_ff                    | Positiontwise_FF   | 2 M   \n",
      "5  | encdec_model.encoder.encoder_layers.0.poswise_ff.linear1            | Linear             | 1 M   \n",
      "6  | encdec_model.encoder.encoder_layers.0.poswise_ff.linear2            | Linear             | 1 M   \n",
      "7  | encdec_model.encoder.encoder_layers.0.self_attn                     | MultiHeadAttention | 1 M   \n",
      "8  | encdec_model.encoder.encoder_layers.0.self_attn.projections_QKVO    | ModuleList         | 1 M   \n",
      "9  | encdec_model.encoder.encoder_layers.0.self_attn.projections_QKVO.0  | Linear             | 262 K \n",
      "10 | encdec_model.encoder.encoder_layers.0.self_attn.projections_QKVO.1  | Linear             | 262 K \n",
      "11 | encdec_model.encoder.encoder_layers.0.self_attn.projections_QKVO.2  | Linear             | 262 K \n",
      "12 | encdec_model.encoder.encoder_layers.0.self_attn.projections_QKVO.3  | Linear             | 262 K \n",
      "13 | encdec_model.encoder.encoder_layers.0.self_attn.attn_wt_dropout     | Dropout            | 0     \n",
      "14 | encdec_model.encoder.encoder_layers.0.layer_norms                   | ModuleList         | 2 K   \n",
      "15 | encdec_model.encoder.encoder_layers.0.layer_norms.0                 | LayerNorm          | 1 K   \n",
      "16 | encdec_model.encoder.encoder_layers.0.layer_norms.1                 | LayerNorm          | 1 K   \n",
      "17 | encdec_model.encoder.encoder_layers.0.heads_dropout                 | Dropout            | 0     \n",
      "18 | encdec_model.encoder.encoder_layers.0.pff_dropout                   | Dropout            | 0     \n",
      "19 | encdec_model.encoder.encoder_layers.1                               | EncoderLayer       | 3 M   \n",
      "20 | encdec_model.encoder.encoder_layers.1.poswise_ff                    | Positiontwise_FF   | 2 M   \n",
      "21 | encdec_model.encoder.encoder_layers.1.poswise_ff.linear1            | Linear             | 1 M   \n",
      "22 | encdec_model.encoder.encoder_layers.1.poswise_ff.linear2            | Linear             | 1 M   \n",
      "23 | encdec_model.encoder.encoder_layers.1.self_attn                     | MultiHeadAttention | 1 M   \n",
      "24 | encdec_model.encoder.encoder_layers.1.self_attn.projections_QKVO    | ModuleList         | 1 M   \n",
      "25 | encdec_model.encoder.encoder_layers.1.self_attn.projections_QKVO.0  | Linear             | 262 K \n",
      "26 | encdec_model.encoder.encoder_layers.1.self_attn.projections_QKVO.1  | Linear             | 262 K \n",
      "27 | encdec_model.encoder.encoder_layers.1.self_attn.projections_QKVO.2  | Linear             | 262 K \n",
      "28 | encdec_model.encoder.encoder_layers.1.self_attn.projections_QKVO.3  | Linear             | 262 K \n",
      "29 | encdec_model.encoder.encoder_layers.1.self_attn.attn_wt_dropout     | Dropout            | 0     \n",
      "30 | encdec_model.encoder.encoder_layers.1.layer_norms                   | ModuleList         | 2 K   \n",
      "31 | encdec_model.encoder.encoder_layers.1.layer_norms.0                 | LayerNorm          | 1 K   \n",
      "32 | encdec_model.encoder.encoder_layers.1.layer_norms.1                 | LayerNorm          | 1 K   \n",
      "33 | encdec_model.encoder.encoder_layers.1.heads_dropout                 | Dropout            | 0     \n",
      "34 | encdec_model.encoder.encoder_layers.1.pff_dropout                   | Dropout            | 0     \n",
      "35 | encdec_model.decoder                                                | Decoder            | 8 M   \n",
      "36 | encdec_model.decoder.decoder_layers                                 | ModuleList         | 8 M   \n",
      "37 | encdec_model.decoder.decoder_layers.0                               | DecoderLayer       | 4 M   \n",
      "38 | encdec_model.decoder.decoder_layers.0.poswise_ff                    | Positiontwise_FF   | 2 M   \n",
      "39 | encdec_model.decoder.decoder_layers.0.poswise_ff.linear1            | Linear             | 1 M   \n",
      "40 | encdec_model.decoder.decoder_layers.0.poswise_ff.linear2            | Linear             | 1 M   \n",
      "41 | encdec_model.decoder.decoder_layers.0.self_attn                     | MultiHeadAttention | 1 M   \n",
      "42 | encdec_model.decoder.decoder_layers.0.self_attn.projections_QKVO    | ModuleList         | 1 M   \n",
      "43 | encdec_model.decoder.decoder_layers.0.self_attn.projections_QKVO.0  | Linear             | 262 K \n",
      "44 | encdec_model.decoder.decoder_layers.0.self_attn.projections_QKVO.1  | Linear             | 262 K \n",
      "45 | encdec_model.decoder.decoder_layers.0.self_attn.projections_QKVO.2  | Linear             | 262 K \n",
      "46 | encdec_model.decoder.decoder_layers.0.self_attn.projections_QKVO.3  | Linear             | 262 K \n",
      "47 | encdec_model.decoder.decoder_layers.0.self_attn.attn_wt_dropout     | Dropout            | 0     \n",
      "48 | encdec_model.decoder.decoder_layers.0.cross_attn                    | MultiHeadAttention | 1 M   \n",
      "49 | encdec_model.decoder.decoder_layers.0.cross_attn.projections_QKVO   | ModuleList         | 1 M   \n",
      "50 | encdec_model.decoder.decoder_layers.0.cross_attn.projections_QKVO.0 | Linear             | 262 K \n",
      "51 | encdec_model.decoder.decoder_layers.0.cross_attn.projections_QKVO.1 | Linear             | 262 K \n",
      "52 | encdec_model.decoder.decoder_layers.0.cross_attn.projections_QKVO.2 | Linear             | 262 K \n",
      "53 | encdec_model.decoder.decoder_layers.0.cross_attn.projections_QKVO.3 | Linear             | 262 K \n",
      "54 | encdec_model.decoder.decoder_layers.0.cross_attn.attn_wt_dropout    | Dropout            | 0     \n",
      "55 | encdec_model.decoder.decoder_layers.0.layer_norms                   | ModuleList         | 3 K   \n",
      "56 | encdec_model.decoder.decoder_layers.0.layer_norms.0                 | LayerNorm          | 1 K   \n",
      "57 | encdec_model.decoder.decoder_layers.0.layer_norms.1                 | LayerNorm          | 1 K   \n",
      "58 | encdec_model.decoder.decoder_layers.0.layer_norms.2                 | LayerNorm          | 1 K   \n",
      "59 | encdec_model.decoder.decoder_layers.0.heads_dropout                 | Dropout            | 0     \n",
      "60 | encdec_model.decoder.decoder_layers.0.pff_dropout                   | Dropout            | 0     \n",
      "61 | encdec_model.decoder.decoder_layers.1                               | DecoderLayer       | 4 M   \n",
      "62 | encdec_model.decoder.decoder_layers.1.poswise_ff                    | Positiontwise_FF   | 2 M   \n",
      "63 | encdec_model.decoder.decoder_layers.1.poswise_ff.linear1            | Linear             | 1 M   \n",
      "64 | encdec_model.decoder.decoder_layers.1.poswise_ff.linear2            | Linear             | 1 M   \n",
      "65 | encdec_model.decoder.decoder_layers.1.self_attn                     | MultiHeadAttention | 1 M   \n",
      "66 | encdec_model.decoder.decoder_layers.1.self_attn.projections_QKVO    | ModuleList         | 1 M   \n",
      "67 | encdec_model.decoder.decoder_layers.1.self_attn.projections_QKVO.0  | Linear             | 262 K \n",
      "68 | encdec_model.decoder.decoder_layers.1.self_attn.projections_QKVO.1  | Linear             | 262 K \n",
      "69 | encdec_model.decoder.decoder_layers.1.self_attn.projections_QKVO.2  | Linear             | 262 K \n",
      "70 | encdec_model.decoder.decoder_layers.1.self_attn.projections_QKVO.3  | Linear             | 262 K \n",
      "71 | encdec_model.decoder.decoder_layers.1.self_attn.attn_wt_dropout     | Dropout            | 0     \n",
      "72 | encdec_model.decoder.decoder_layers.1.cross_attn                    | MultiHeadAttention | 1 M   \n",
      "73 | encdec_model.decoder.decoder_layers.1.cross_attn.projections_QKVO   | ModuleList         | 1 M   \n",
      "74 | encdec_model.decoder.decoder_layers.1.cross_attn.projections_QKVO.0 | Linear             | 262 K \n",
      "75 | encdec_model.decoder.decoder_layers.1.cross_attn.projections_QKVO.1 | Linear             | 262 K \n",
      "76 | encdec_model.decoder.decoder_layers.1.cross_attn.projections_QKVO.2 | Linear             | 262 K \n",
      "77 | encdec_model.decoder.decoder_layers.1.cross_attn.projections_QKVO.3 | Linear             | 262 K \n",
      "78 | encdec_model.decoder.decoder_layers.1.cross_attn.attn_wt_dropout    | Dropout            | 0     \n",
      "79 | encdec_model.decoder.decoder_layers.1.layer_norms                   | ModuleList         | 3 K   \n",
      "80 | encdec_model.decoder.decoder_layers.1.layer_norms.0                 | LayerNorm          | 1 K   \n",
      "81 | encdec_model.decoder.decoder_layers.1.layer_norms.1                 | LayerNorm          | 1 K   \n",
      "82 | encdec_model.decoder.decoder_layers.1.layer_norms.2                 | LayerNorm          | 1 K   \n",
      "83 | encdec_model.decoder.decoder_layers.1.heads_dropout                 | Dropout            | 0     \n",
      "84 | encdec_model.decoder.decoder_layers.1.pff_dropout                   | Dropout            | 0     \n",
      "85 | encdec_model.classifier                                             | Classifier         | 15 K  \n",
      "86 | encdec_model.classifier.shared_embed                                | Embedding          | 15 K  \n",
      "87 | encdec_model.inp_layer                                              | Sequential         | 15 K  \n",
      "88 | encdec_model.inp_layer.scaled_embed                                 | ScaledEmbedding    | 15 K  \n",
      "89 | encdec_model.inp_layer.position_encoder                             | PositionEncoder    | 0     \n",
      "90 | encdec_model.inp_layer.embed_dropout                                | Dropout            | 0     \n",
      "91 | encdec_model.out_layer                                              | Sequential         | 15 K  \n",
      "92 | loss_criterion                                                      | LabelSmoothedLoss  | 0     \n",
      "93 | loss_criterion.KLdiv_criterion                                      | KLDivLoss          | 0     \n",
      "94 | loss_criterion.logprob                                              | LogSoftmax         | 0      \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/playground/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/anaconda/envs/playground/lib/python3.7/site-packages/ipykernel_launcher.py:55: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.8<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">test-dummy</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/chucooleg/pytorchlightning_test\" target=\"_blank\">https://wandb.ai/chucooleg/pytorchlightning_test</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/chucooleg/pytorchlightning_test/runs/1l2umpf7\" target=\"_blank\">https://wandb.ai/chucooleg/pytorchlightning_test/runs/1l2umpf7</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201113_021551-1l2umpf7</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type              | Params\n",
      "-----------------------------------------------------\n",
      "0 | encdec_model   | EncoderDecoder    | 14 M  \n",
      "1 | loss_criterion | LabelSmoothedLoss | 0     \n",
      "/anaconda/envs/playground/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10a2e442ffa4d5a890bed46a3c20298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-15-67416ef3e276>\u001b[0m(49)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     47 \u001b[0;31m        \u001b[0;31m# inp X[:,:]: tensor([<go>, ... , <stop>, pad, pad, pad ...])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     48 \u001b[0;31m        \u001b[0;31m# out Y[:, :-1]: tensor([<go>, ... , <stop>, pad, pad ...])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 49 \u001b[0;31m        \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencdec_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     50 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     51 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m<ipython-input-15-67416ef3e276>\u001b[0m(54)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     52 \u001b[0;31m        \u001b[0;31m# loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     53 \u001b[0;31m        \u001b[0;31m# target Y[:, 1:]: tensor([ ... , <stop>, pad, pad ...])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 54 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     55 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     56 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m<ipython-input-15-67416ef3e276>\u001b[0m(58)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     56 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     57 \u001b[0;31m        \u001b[0;31m# acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 58 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mstudent_force_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     59 \u001b[0;31m            \u001b[0;31m# doesn't include <go>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     60 \u001b[0;31m            y_hat = self.generate_sequence(\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m<ipython-input-15-67416ef3e276>\u001b[0m(70)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     68 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     69 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 70 \u001b[0;31m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m            \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     72 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m<ipython-input-15-67416ef3e276>\u001b[0m(76)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     74 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     75 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 76 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     77 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     78 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_nb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "## W&B References\n",
    "# https://docs.wandb.com/library/integrations/lightning\n",
    "# colab example\n",
    "# https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch-lightning/Supercharge_your_Training_with_Pytorch_Lightning_%2B_Weights_%26_Biases.ipynb\n",
    "# step by step guide\n",
    "# https://wandb.ai/cayush/pytorchlightning/reports/Use-Pytorch-Lightning-with-Weights-Biases--Vmlldzo2NjQ1Mw\n",
    "\n",
    "\n",
    "hparams = {\n",
    "    'd_model': 512,\n",
    "    'd_ff': 2048,\n",
    "    'max_len': 30, #!\n",
    "    'num_heads': 2,\n",
    "    'embed_dropout': 0.0,\n",
    "    'attn_wt_dropout': 0.0,\n",
    "    'heads_dropout': 0.0,\n",
    "    'pff_dropout': 0.0,\n",
    "    'N_enc': 2,\n",
    "    'N_dec': 2,\n",
    "    'start_idx': 30, #!\n",
    "    'padding_idx': 0,#! \n",
    "    'stop_idx': 1,   #!\n",
    "    'smoothing_const': 0.1,\n",
    "    'temperature_const': 1.0,\n",
    "    'adam_beta1': 0.9,\n",
    "    'adam_beta2': 0.98,\n",
    "    'adam_epsilon': 1e-9,\n",
    "    'warmup_steps': 12000,\n",
    "    'vocab_size': 31 #!\n",
    "}\n",
    "\n",
    "# model\n",
    "my_transformer = Transformer(hparams)\n",
    "print(pl.core.memory.ModelSummary(my_transformer, mode='full'),'\\n')\n",
    "\n",
    "# data\n",
    "# toy_data = ToyDataModule(batch_size=100, V=hparams['vocab_size'], seed=40, context_len=hparams['max_len'], tot_size=500)\n",
    "polyexp_data = PolynomialExpansionDataModule(\n",
    "    batch_size=100, \n",
    "    data=polyexp_jsondata,\n",
    "    pad_idx=hparams['padding_idx'], \n",
    "    stop_idx=hparams['stop_idx'], \n",
    "    start_idx=hparams['start_idx'])\n",
    "\n",
    "# logger\n",
    "wd_logger = WandbLogger(name=\"test-dummy\",project='pytorchlightning_test')\n",
    "\n",
    "# trainer\n",
    "trainer = pl.Trainer(\n",
    "    gpus=0, min_epochs=2, max_epochs=5, \n",
    "    logger=wd_logger,log_gpu_memory='all',\n",
    "    precision=32, amp_backend='apex', amp_level='O3' )\n",
    "\n",
    "# fit!\n",
    "with torch.autograd.detect_anomaly():\n",
    "    trainer.fit(my_transformer, polyexp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, X, Y, student_force_acc=False):\n",
    "        '''\n",
    "        X : (b, inp_len)\n",
    "        Y : (b, out_len)\n",
    "        '''\n",
    "\n",
    "        import pdb; pdb.set_trace()\n",
    "        # fwd\n",
    "        # inp X[:,:]: tensor([<go>, ... , <stop>, pad, pad, pad ...])\n",
    "        # out Y[:, :-1]: tensor([<go>, ... , <stop>, pad, pad ...])\n",
    "        logits = self.encdec_model(X[:,:], Y[:, :-1])\n",
    "        \n",
    "        import pdb; pdb.set_trace()\n",
    "        # loss\n",
    "        # target Y[:, 1:]: tensor([ ... , <stop>, pad, pad ...])\n",
    "        loss = self.loss_criterion(logits, Y[:, 1:])\n",
    "\n",
    "        import pdb; pdb.set_trace()\n",
    "        # acc\n",
    "        if student_force_acc:\n",
    "            # doesn't include <go>\n",
    "            y_hat = self.generate_sequence(\n",
    "                X, \n",
    "                hparams['start_idx'], \n",
    "                hparams['padding_idx'], \n",
    "                hparams['max_len'])         \n",
    "        else:\n",
    "            # doesn't include <go>\n",
    "            _, y_hat = torch.max(logits, dim=-1)\n",
    "        \n",
    "        import pdb; pdb.set_trace()\n",
    "        try:\n",
    "            acc = self.accuracy(y_hat, Y[:, 1:])\n",
    "        except:\n",
    "            import pdb; pdb.set_trace()\n",
    "\n",
    "        import pdb; pdb.set_trace()\n",
    "        return loss, acc, y_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
